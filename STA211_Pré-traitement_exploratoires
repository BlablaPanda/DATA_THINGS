Méthodes descriptives:

1 Introduction

  méthode statistiques pour néttoyer les données manquates,valeurs erronées, valeurs abberantes etc

2 Données German Credit
  1000 dossiers, 300 impayés, 20 variable
  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data
  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc
  
3. Analyse univariée
   L’analyse univariée des variables renseigne sur leur distribution, dite distribution marginale (par opposition à la distribution jointe qui correspond à la distribution d’un ensemble de plusieurs variables). Cette analyse permettra notamment d’identifier des valeurs aberrantes, et de connaître des caractéristiques de la distribution (e.g. son caractère gaussien). 
   Une donnée sera considérée comme aberrante si elle n’est pas issue du même modèle que celui qui tient pour la majorité des données. 
   n: nombre d'indivius
   X: une variables
   
   3.1 Représentations graphiques
   
    3.1.1 Variables qualitatives
      On appelle variable qualitative une variable dont les valeurs sont non-numériques(<>codage) , on parle de modalités(valeurs possibles d'attributs(column))
      3.1.1.1 Variables qualitatives nominales: 
              La fréquence absolue de la modalité
              La fréquence relative de la modalité
              -> identifier modalités rares et trop grand nombre de modalités sur des variables explicatives d’un modèle peut entraîner une grande instabilité sur l’estimation des coefficients de ce modèle.
      3.1.1.2 Variables qualitatives ordinales:
              fréquences absolues cumulées (permet de savoir l'interface de une plage de valeur ?)
              fréquences relatives cumulées
    
    3.1.2 Varaible quantitatives   
    
     3.1.2.1 Variables quantitatives dicrètes :
      -Une variable quantitative discrète est une variable à valeurs dans un espace dénombrable
      -Quand le nombre de valeurs observées devient élevé, il pourra être parfois intéressant d’utiliser une représentation tige-et-feuille(https://fr.khanacademy.org/math/statistics-probability/displaying-describing-data/quantitative-data-graphs/a/stem-and-leaf-plots-review).
      -Statistique d’ordre:our une série statistique (x1,…,xn), on range ses valeurs dans l’ordre croissant x(1)≤x(2)≤…≤x(n) le vecteur (x(1),…,x(n)) est appelé statistique d’ordre de la série  (https://fr.wikipedia.org/wiki/Statistique_d%27ordre)
      -Fonction de répartition empirique:
     3.1.2.2 Variables quantitatives continues 
      -Classe, Amplitude, Effectif d'une classe, Fréquence d'une classe
      -Le nombre de classes pourra par exemple être choisi selon la règle de Sturges préconisant de choisir k=1+ln(n)/ln(2) classes
      -histogramme: Un histogramme dont les amplitudes des classes sont fixes sera appelé histogramme à pas fixe, dans le cas contraire on parlera d’histogramme à pas variable. 
        Age avec une queue à droite. On pourra parfois être amené à transformer cette variable de façon à se ramener à une distribution approximativement normale (e.g. si on souhaite par la suite effectuer une analyse discriminante linéaire qui repose sur la multinormalité des variables). 
        -queue à droit: Les transformations les plus courantes sont la transformation logarithmique ou racine carrée pour les variables positives (en ajoutant éventuellement la valeur 1 pour gérer les zéros) asymétriques à droite, 
        -queue à gauche: tandis qu’on utilisera plutôt une transformation puissance (2 ou 3) pour les asymétries à gauche. 
        -Dans le cas de proportion, on pourra utiliser la transformation arcsinus.
        un histogramme peut être vu comme une estimation de la fonction de densité d’une variable continue
       
   3.2 Indicateurs numériques
   
    3.2.1 Indicateurs de tendance centrale
      l’ordre de grandeur de la variable en donnant une valeur autour de laquelle les valeurs de la série se répartissent
      3.2.1.1 Moyenne empirique, moyenne, médiane, mode(e mode est défini comme la valeur la plus fréquente de la série)
    
    3.2.2 Indicateur de dispersion  
      sur la variabilité de la série, généralement autour d’un indicateur de tendance centrale
      3.2.2.1 Variance empirique
      3.2.2.2 Coefficient de variation empirique : En pratique, on utilise le seuil de 0.15 pour établir une faible/forte variabilité
      3.2.2.3 Etendue: la différence du maximum et du minimum de la série,c’est un indicateur évidemment très sensible aux valeurs aberrantes. Quand on dispose de mesures d’un même caractère à des différents temps, la comparaison des étendues pour les différents temps permettra de détecter des valeurs aberrantes.
      3.2.2.4 Quantiles:la série ordonnée en un certain nombre de parties de même effectif 
              diagramme quantile-quantile ou qq-plot. Si les quantiles empiriques et théoriques sont proches, alors il sera raisonnable de penser que la distribution de la variable correspond bien à la distribution théorique considérée.
      3.2.2.5 Distance inter-quartiles
      3.2.2.6 Représentation
              une boîte à moustaches( diagramme en boîte,boxplot):https://www.stat4decision.com/fr/le-box-plot-ou-la-fameuse-boite-a-moustache/
    
    3.2.3 Indicateurs de forme
      les indicateurs de forme qui permettent notamment d’apprécier le caractère gaussien des données
      3.2.3.1 Coefficient d’asymétrie: Le coefficient d’asymétrie de Fisher vaut 0 pour une série dont la répartition est symétrique (e.g. loi normale), est positif si la queue de la distribution est à droite (e.g. loi exponentielle), et négatif si la queue de la distribution est à gauche. Il est sensible aux variations des valeurs aberrantes, au même titre que la moyenne ou la variance.
      3.2.3.2 Coefficient d’aplatissement: Le coefficient d’aplatissement de Fisher sert à comparer la concentration des valeurs à celle d’une loi normale centrée pour laquelle ce coefficient vaut 3. Un coefficient d’aplatissement positif indique une densité est plus concentrée que celle d’une distribution gaussienne, sinon il indique une densité moins concentrée. Cet indicateur, basé sur la moyenne empirique, est sensible aux valeurs aberrantes.
      
4 Analyse bivarié
      L’analyse univariée ne renseigne pas sur les relations entre les variables. On la complète par l’étude des relations entre les variables deux à deux, appelée analyse bivariée
      L’analyse bivariée s’effectue à nouveau par l’intermédiaire de graphiques et également par la lecture d’indicateurs quantifiant la liaison entre les variables. Ceux-ci dépendent à nouveau de la nature des deux variables étudiées.
    
    4.1 Lien entre variables quantitatives  
      4.1.1 Représentation graphique: 
            nuage de points,centrées-réduite ou des échelles telleques que ce soit sensiblement ces variables là qye l'on représente.
      4.1.2 Corrélation:
            le coefficient de corrélation linéaire (ou son estimation) est compris entre -1 et 1.
            l’indépendance entre les variables implique que ρ=0, la nullité du coefficient n’implique pas l’indépendance entre les variables, mais simplement une absence de lien linéaire.
            Quand le lien entre les variables n’est plus linéaire, on privilégiera un coefficient de corrélation basé sur les rangs des observations (cf Table 4.2) comme le coefficient de Spearman (noté rs) ou coefficient de Kendall (noté τ). Ces coefficients sont robustes aux valeurs aberrantes, mais ne permettent de détecter que des relations monotones entre les variables (tout comme le coefficient de corrélation linéaire).
            Le coefficient de Spearman: évalue la corrélation linéaire sur les rangs des observations, plutôt que sur les observations elles-mêmes.
            Le coefficient de Kendall:entre -1 et 1. Il vaut 1 si les paires sont toutes concordantes, et -1 si elles sont toutes discordantes. L’indépendance entre les variables implique la nullité du coefficient, mais la réciproque est à nouveau fausse.
    
    4.2 Lien entre variables quantitatives et qualitatives
      4.2.1  Représentation graphique
       la distribution de la variable quantitative en fonction des modalités de la variable qualitative
      4.2.2 Rapport de corrélation
       ce coefficient évalue (à la fonction racine carré près) la part de variance de la variable quantitative qui peut être expliquée par la variable qualitative.  
       La variance expliquée correspond à la dispersion des valeurs moyennes au sein de chaque sous-ensemble définis par la variable qualitative. 
       Plus la variance expliquée est proche de la variabilité de Y, plus le rapport de corrélation est proche de 1. Dans le cas où les moyennes au sein de chaque sous ensemble sont identiques, la variance expliquée est nulle et le rapport de corrélation vaut 0.
       ?Le test de Welch , ?un test de Fisher
    
     4.3 Lien entre variables qualitatives  
      4.3.1 Table de contingence ?
      4.3.2 Représentation graphique
      -graphique en mosaïque  
      4.3.3 Khi deux
      -Khi-deux
      -Coefficient T de Tschuprow
      -Coefficient V de Cramer
      es coefficients T de Tschuprow et V de Cramer sont compris entre 0 et 1, une valeur élevée traduisant une liaison forte, et une valeur proche de 0 une liaison faible.
      
5 Analyse multivariée

  le nombre de variables devient élevé, il n’est plus envisageable de regarder tous les couples de variables deux à deux, car leur nombre devient rapidement trop grand, on préférera alors utiliser les approches multivariées.
  -Les méthodes d’analyse factorielle sont utilisées pour identifier les relations entre variables ainsi que les ressemblances entre individus. Ces méthodes reposent sur des approches géométriques dont le principe est de réduire la dimension du jeu de données en effectuant des projections des données sur des espaces de dimension inférieure
  -Les méthodes de classification (non-supervisées) permettent de répondre aux mêmes objectifs, en construisant une partition des individus, ou des variables, à partir de l’ensemble des données.
  
  5.1 Données quantitatives
    5.1.1 Analyse en composantes principales (ACP)
      5.1.1.1 Principe de la méthode
      l’ACP consiste à rechercher un sous-espace (par exemple un plan) dans le nuage des individus tel que la projection du nuage sur ce sous-espace résume au ``mieux’‘le nuage initial. Le critère utilisé pour mesurer la qualité de la projection est l’inertie. 
      L’inertie est une mesure de dispersion d’un nuage de points, elle peut être vue comme une généralisation de la notion de variance. 
      L’objectif de l’ACP consiste alors à rechercher un sous-espace tel que l’inertie du nuage projeté sur ce sous-espace soit la plus grande possible, de façon à ce que la diversité des positions des individus projetés reflète au mieux la diversité des profils avant projection. 
      https://www.youtube.com/watch?v=FgakZw6K1QQ
      http://maths.cnam.fr/IMG/pdf/A-C-P-.pdf
      https://www.youtube.com/watch?v=8qw0bNfK4H0
      http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/100454_AnaDo_ACP_cours_slides.pdf
      
      5.1.1.2 Individus et variables supplémentaires
      On calcule la contribution d’un individu à la construction d’un plan en sommant les contributions à la construction des différents axes qui le composent. La simple lecture des contributions permet ainsi d’identifier les potentielles valeurs aberrantes. Plutôt que de supprimer purement et simplement les individus aberrants (i.e. aux grandes contributions), on peut les considérer comme des individus supplémentaires (ou individus illustratifs).
      Il s’agit de projeter ces individus sur le sous-espace sans qu’ils interviennent dans la construction des axes. Pour cela, on leur affecte un poids nul, ce qui implique que les axes seront construits sans ces individus, et on les projette ensuite a posteriori sur le sous-espace une fois les axes construits, ce qui permet néanmoins de les positionner par rapport aux autres. Par opposition, les individus qui contribuent à la construction des axes sont appelés des individus actifs.
    
    5.1.2 Application au jeu German Credit
    cercle des corrélations met en évidence deux groupes de variables positivement corrélées entre elles
    l’ACP peut permettre d’identifier d’éventuelles valeurs aberrantes via la visualisation du graphe des individus
    il est possible d’analyser les relations entre les variables qualitatives et les composantes principales (résumant les relations entre variables quantitatives). Ceci permet de faire le lien entre les coordonnées des individus sur un axe et ces variables. Pour cela on peut regarder directement le rapport de corrélation entre ces variables et les différentes composantes
   
   5.1.2.1 Choix du nombre de dimensions
     5.1.2.1.1 Règle de Kaiser
      Il consiste à identifier, dans le cadre d’une ACP normée, le nombre de valeurs propres supérieures à 1.
     5.1.2.1.2 Règle du coude 
      Il s’agit de déterminer l’indice de l’axe pour lequel l’inertie portée est ``nettement’’ inférieure à celle des axes précédents. 
     5.1.2.1.3 Autres
  
  5.2 Données qualitatives
  
  5.2.1 Analyse des correspondances multiples (ACM)
  http://maths.cnam.fr/IMG/pdf/ANALYSE_DES_CORRESPONDANCES_MULTIPLES-2012-2_cle838d4f.pdf
  https://www.youtube.com/watch?v=bihScz3OXbw
  5.2.2 Application au jeu German Credit
  
   les modalités rares sont ici gérées par ventilation. La ventilation consiste à réaffecter chaque modalité rare à une modalité plus fréquentes de façon aléatoire. 
    
