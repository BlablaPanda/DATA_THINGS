I.Evaluation d'un moteur de recherche
Positif       :rslt
Négatif       :pas de rslt
Faux posistifs:doc non pertinent inclus dans le rslt
Faux négatifs :doc pertinents  qui ne sont pas inclus dans le rslt

precision=vrais positif/positif faux+vrais
recall=vrais positif/vrais positif + faux négatif (voir le diapo)

  Matrice avec documents en ligne
  On sélectionne un ensemble de mots(termes) consitutant notre vocabulaires
  --Perdre l'ordre de mot
  on prend les vecteurs binaires des termes 
  --Trop cher au niveau de calcul
  ->solution1:
  liste inversée/matrice inversée: une liste par terme; dans chque liste, 1 pour les documents contenant le terme
  --difficile maj 
  ->solution1+:elimiler les zero et mettre l'id de doc
  ->solution1++ trier la liste
  
II.Indexation

un moteur de recherche essaie d'analyser des documents
1.analyser le type des données
2.tansferer les textes bruts à une recherche prciseé.

Role d'analyse
normalisation/unification pour être moins dépendant de la formùe du texte
par exemple "Loup" -> louve,loup,loups
traduction=> Synonoymes -> loup=wolf loup=pretateur ?
! plus on normalise plus diminue la précision
! plus on noramlise plus on améliore le rappel
! le même tranformation doit être applicquée aux documents et à la requête

Les phases de l'analyse
-decter les langues,
-Tokenization : découpage du texte en "mots"
-Normalisation : majuscules ? acronymes ? apostrophes ? accents ?
-Stemming("racinisation") lemmatization 
   stemming morphologique: retire les pluriels, marque de genre, genre, conjuaison
   stemming lexial : 
   stemming phonétique: corectionfautes de frappes
-stop words, quels mots garder ? (le un à de...)

III. Elerstique search

Le schéma donne la liste de tous les champs d'un document.
Cela permet de faire la recherche sur les documents.
"mappings"{
"movie" (type):{ 
"actors"(type):{ "type":"nested"(tableau objet)
champs predefini
"_all": concatenation de tous les caractères
"_source": index + base documentaire (- pris bcp de memoire, difficile de modifier le shema de document car il faut recréer l'index)

index indique si le champ peut être utilisé dans une recherche
store indique si la valeur du champ est stockée dans l'index l'option store permet de considérer elesticsearche comme une base de données
c'estpas une bonne idée d'utiliser elestique serarch comme une base de donnée (pbm de maj)
c'est mieux d'utiliser le moteur de recherche pour trouver les resources de données et cherche les données dans le resource

Moteurs de recherche

Opensource: Solr et ElastiSearch a basé sur l'index reversé: Lucene (par apache).
Archetecture: Base documentiare +base d'index documentaire
Elasticsearch:
  logstash,l'ETL pour extraire,transformer et charger les données
  ElasticSearch, le moteur 
  Kibana pour produire des tableaux de bord de surveillance


Installation via Docker image
1.Commençons par l’installation avec Docker. Voici une commande qui devrait fonctionner sous tous les systèmes et mettre ElasticSearch en attente sur le port 9200.
docker run -d --name es1  -p 9200:9200 -p 9300:9300 elasticsearch:2.4 \
       -Des.index.number_of_shards=1 \
       -Des.index.number_of_replicas=0
2.Vous pouvez obtenir l’IP de votre conteneur (que l’on a nommé es1) avec la commande Bash suivante:

sudo docker inspect --format '{{ .NetworkSettings.IPAddress }}' es1


Connect par navigateur: 
machine ip docker:porte conteneur
http://192.168.99.100:9200

interface:

docker exec es1 plugin install lmenezes/elasticsearch-kopf ->http://192.168.99.100:9200/_plugin/kopf/#!/cluster
docker run -p 5000:5000 elastichq/elasticsearch-hq ->http://192.168.99.100:5000

importation (cd le repertoire de fichier json):

curl -s -XPOST http://192.168.99.100:9200/_bulk/ --data-binary @movies-elastic.json

par navigateur pour interoger les données:

http://192.168.99.100:9200/nfe204/movies/_search?q=Logan
http://192.168.99.100:9200/_plugin/kopf


#Recherche Boolean
0. http://192.168.99.100:9200/_plugin/kopf -> reset
1.méthode: post + path: nfe204/_search


{
  "query": {
    "query_string": {
      "query": "meurtrier"
    }
  }
}



#Analyse des documents 

couper les données -> analyse de type de données-> transformations(femin/masculant/syno)
!Plus on normalise plus on diminue la précsion mais plus on améliore le rappel
!Transformation -> à documents mais aussi à requoete

déf:
Tokenization: découpage du texte
Normalisation: majuscules acronymes
Stemming/lemmatization: racinisation
Stop words: quels mots garder ? (le,un,à,de -> peu informatifs) 


quize ? ? c B C ? B précison A rappel C C 
cout d'une recherche un index avec inversé->B
énonceé rechere booléenne ->B
exo1
q1=50/60
q2=rien


Quiz
1.NoSql vs elstic search ->index est rigide, c'est diffcile de changer doc B est fausse
2.B
3.A

Quiz
1.C
2.B
3.A

Quiz
1.Tokenisation
C
2.A

Quiz
1.intrus C
2.indexé B

