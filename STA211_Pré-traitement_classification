1 Introduction

Les méthodes d’analyse factorielle permettent de mettre en évidence les ressemblances entre individus 
ainsi que les liaisons entre variables, 
et ainsi d’identifier des groupes (ou classes) d’individus ou de variables similaires. 
Néanmoins, ces groupes restent assez subjectifs dans le sens où les méthodes d’analyse factorielle ne permettent pas d’affecter de façon automatique et claire un objet (individu ou variable) à un groupe.

La classification a pour objectif de former une (ou plusieurs) partition(s) d’objets, i.e. de définir K groupes d’objets (C1,...,CK) sans recouvrements ni intersections, de sorte que chaque objet soit affecté à un groupe et à un seul. 

On parle également de segmentation, de clustering, ou de classification non-supervisée.

individu en ligne, variable en column

Ces groupes d’individus ne sont pas connus a priori

http://maths.cnam.fr/IMG/pdf/Classification-2008-2.pdf


2 Mathodes de partitionnement

Les méthodes de partitionnement consistent à définir une partition de l’ensemble des individus en K (défini à l’avance) groupes.
k-means: centres mobiles

  2.1 Agrégation autour des centres mobiles
  
      déjà définit dans ACP
      
      - la distance usuelle
      - la distance usuelle pondérée par l’inverse de la variance
      - la distance de Mahalanobis
      
       la pondération par l’inverse de la matrice de variance-covariance permet de diminuer l’influence de la covariance entre les variables.
       on cherchera à minimiser l’inertie au sein des groupes constitués (inertie intra-classe), de façon à avoir des classes les plus homogènes possibles
       Inertie Totale=Inertie inter-classes+Inertie intra-classe
       K désigne le nombre de classes et k l’indice d’une de ces classes, 
       nk désigne l’effectif de la classe Ck, 
       G est le barycentre du nuage de points 
       Gk le barycentre du sous nuage défini par la classe Ck.
     
     -> Trop grand pour mesure le nombre de partitions possible en K
     -> L’algorithme d’agrégation autour des centres mobiles fournit une solution localement optimale à ce problème.
     
      2.1.1 Principe
      1.insitialisation: au hasard = centres / noyau
      2.Répéter: allouer,retrouver nouveau noyau, s'arrêter si le critère de variance intra-classe ne diminue plus
      https://www.kdnuggets.com/2018/06/5-clustering-algorithms-data-scientists-need-know.html
      
      2.1.2 Propriétés
      
      2.1.3 Choix du nombre de classes
      
      2.1.4 Formes Fortes
      
      formes fortes:intersections des partitions obtenues
                      Il est important de noter que le label (i.e. le numéro) d’une classe est purement arbitraire et que par conséquent, pour deux exécutions de l’algorithme, les partitions peuvent être identiques alors que les numéros des classes sont permutés
      
      si pour deux initialisations de l’algorithme (ou plus) un regroupement d’individus est toujours au sein d’une même classe, alors ceci indique que regroupement est stable
      
  2.2 Autres méthodes de patitionnement
  
  k−means de MacQueen :
    réaffecter les centres dès qu’un individu change de classe, alors que précédemment l’étape de mise à jour des centres n’avait lieu qu’une fois tous les individus réalloués. 
    Cette variante accélère la convergence, mais rend l’algorithme dépendant à l’ordre dans lequel les individus sont réalloués.
  nuées dynamiques Diday: 
    un mode de représentation d’un groupe d’individus différent de celui du barycentre
    cela permet de corriger l’influence d’éventuelles valeurs extrêmes sur le calcul du barycentre.
   méthode isodata par Ball and Hall :
    un raffinement de la technique de réallocation dans la méthode des centres mobiles avec une gestion dynamique du nombre de classes
    Elle permet notamment d’empêcher la formation de classes d’effectifs trop faibles ou de diamètres trop grands.
 
3 Méthodes hiérarchiques    
 
classification géométriques, Elles visent à construire non pas une partition, mais une suite de partitions imbriquées les unes dans les autres (arbre hiérarchique ou dendogramme).
https://www.youtube.com/watch?v=SE_4dLh5vXY

  3.1 Distance entre individus ou groupes
  
  La méthode de classification ascendante hiérarchique (CAH)
  
  mesure de dissimilarité entre individus :  une fonction de l’espace
  
  3.2 Algorithme de classification ascendante hiérarchique
  
  mesure rassemblance entre groupe: saut miminmum,lien complet, critère de ward
  
  => arbre -> coupe
  intra classe petit et inter classe grand
  inertie total = inertie intra + inertie inter (Theoreme de Huygens)
  -> maximum intertie inter ou miniminiser intertie intra
  critère ward pemet d'éviter l'effet de chaine

    3.2.1 Construction de la suite de partitions imbriquées:
    
    3.2.2 Construction de l’arbre hiérarchique
  3.3 Choix du nombre de classes
      
    des individus d’une même classe partagent les mêmes propriétés (compacité).
    des individus appartenant à des classes différentes aient peu de propriétés en commun (séparabilité).
  
  3.4 Propriétés
  
    3.4.1 Choix de la mesure de dissimilarité
    
    3.4.2 Choix du critère d’agrégation
    
   
    
4 Méthodes mixtes    

L’idée de la classification mixte est alors de commencer par effectuer une agrégation autour des centres mobiles pour un grand nombre de classes (disons 50 pour fixer les idées). On réduit ainsi le nombre d’éléments à classer passant d’un nombre n d’individus potentiellement grand à un nombre modéré de classes. 

5 Description des classes

  5.1 Variables quantitatives
  5.2 Variables qualitatives
  
6 Données qualitatives
  Algorithme des k-modes
  Quelques exemples de distances Euclidiennes
  
 7 Complémentarité de l’analyse factorielle et des méthodes de classification
 
 +il est généralement difficile d’interpréter les axes au-delà du plan principal. 
 la visualisation des premiers axes ne reflète pas l’intégralité de la structure des données car une part de l’inertie est aussi portée par les derniers axes qui ne sont pas analysés.
 La classification, elle, est effectuée sur l’intégralité des données. 
 elle va permettre de visualiser l’information portée par l’ensemble des axes et donc d’enrichir l’interprétation et corriger les déformations liées à l’opération de projection.
 
 +Aussi, ces méthodes d’analyse factorielle sont sensibles aux individus aberrants, ces individus influençant grandement la construction des axes. Au contraire, les méthodes de classification (hiérarchiques en particulier) sont peu sensibles localement aux points marginaux isolés : ces individus ne seront pas agrégés avec les autres dans la partie basse du dendogramme.
  
 + La représentation des classes sur les plans va permettre de simplifier la description des ressemblances et oppositions entre individus par une donnée plus synthétique
